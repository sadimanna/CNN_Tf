{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg13.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sadimanna/CNN_Tf/blob/master/vgg13.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "0ltUA2YM3tlO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ]
    },
    {
      "metadata": {
        "id": "baX50H4y3zQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time, random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJYs0vrp38Sc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Suppress Warnings"
      ]
    },
    {
      "metadata": {
        "id": "fL36Ht093-HR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
        "warnings.simplefilter(\"ignore\", FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HhhnRcT-4JiG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define Support Functions**"
      ]
    },
    {
      "metadata": {
        "id": "vtFTouqo4Oac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Function for Weights***"
      ]
    },
    {
      "metadata": {
        "id": "ALexlDce4EX_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_weights(name,shape):\n",
        "\treturn tf.get_variable(name=name,shape=shape,initializer = tf.contrib.layers.xavier_initializer(uniform=False),regularizer = tf.contrib.layers.l2_regularizer(tf.constant(0.0005, dtype=tf.float32)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YROOy93o4Tph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Function for Biases***"
      ]
    },
    {
      "metadata": {
        "id": "LTuy9Blt4Wlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_bias(name,shape):\n",
        "\treturn tf.get_variable(name=name,shape=shape,initializer = tf.zeros_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucytJhxz4Zb_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Convolutional Layer Function***"
      ]
    },
    {
      "metadata": {
        "id": "FQPCS9EX4cN5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(inp,name,kshape,s):\n",
        "\twith tf.variable_scope(name) as scope:\n",
        "\t\tkernel = get_weights('weights',shape=kshape)\n",
        "\t\tconv = tf.nn.conv2d(inp,kernel,[1,s,s,1],'SAME')\n",
        "\t\tbias = get_bias('biases',shape=kshape[3])\n",
        "\t\tpreact = tf.nn.bias_add(conv,bias)\n",
        "\t\tconvlayer = tf.nn.relu(preact,name=scope.name)\n",
        "\treturn convlayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFlUaXeX4fSC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Max Pool layer Function***"
      ]
    },
    {
      "metadata": {
        "id": "wlviAoDU4irw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def maxpool(inp,name,k,s):\n",
        "\treturn tf.nn.max_pool(inp,ksize=[1,k,k,1],strides=[1,s,s,1],padding='SAME',name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HUhJlNTV4kjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Loss Function***"
      ]
    },
    {
      "metadata": {
        "id": "HZYaLLSq4nCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss(logits,labels):\n",
        "\tlabels = tf.reshape(tf.cast(labels,tf.int64),[-1])\n",
        "\t#print labels.get_shape().as_list(),logits.get_shape().as_list()\n",
        "\tcross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits,name='cross_entropy_per_example')\n",
        "\tcross_entropy_mean = tf.reduce_mean(cross_entropy,name='cross_entropy')\n",
        "\ttotal_loss = tf.add(tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)),cross_entropy_mean,name='total_loss')\n",
        "\treturn total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WbJqxFOG4sNg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Accuracy Function***"
      ]
    },
    {
      "metadata": {
        "id": "itUNrtQS4wJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(logits,true_labels):\n",
        "\tpred_labels = tf.argmax(logits,1)\n",
        "\ttrue_labels = tf.cast(true_labels,tf.int64)\n",
        "\t#print pred_labels.get_shape().as_list(),true_labels\n",
        "\tcorrect_pred = tf.cast(tf.equal(pred_labels, true_labels), tf.float32)\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "\treturn accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpI-9zFc4w_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Augmentation Supplementary Functions***"
      ]
    },
    {
      "metadata": {
        "id": "0jZ2Gqgs42-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_new_size():\n",
        "\tnew_size = 96 + random.choice([24,16,0])\n",
        "\treturn [new_size,new_size]\n",
        "\t\n",
        "def get_random_augmentation_combinations(length):\n",
        "\tout = [False,True]\n",
        "\treturn [random.choice(out) for i in xrange(length)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1ua8u_I44L7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Function for getting Training Images***"
      ]
    },
    {
      "metadata": {
        "id": "2UWwwTCb4-7j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_all_images(img_file):\n",
        "\timages = np.fromfile(img_file,dtype=np.uint8).astype(np.float32)\n",
        "\timages = np.reshape(images,(-1,3,96,96))\n",
        "\timages = np.transpose(images,(0,3,2,1))\n",
        "\tprint 'Normalizing Inputs...'\n",
        "\trmean = np.mean(images[:,:,:,0])\n",
        "\tgmean = np.mean(images[:,:,:,1])\n",
        "\tbmean = np.mean(images[:,:,:,2])\n",
        "\trstd = np.std(images[:,:,:,0])\n",
        "\tgstd = np.std(images[:,:,:,1])\n",
        "\tbstd = np.std(images[:,:,:,2])\t\n",
        "\timages[:,:,:,0] = (images[:,:,:,0] - rmean)#/rstd\n",
        "\timages[:,:,:,1] = (images[:,:,:,1] - gmean)#/gstd\n",
        "\timages[:,:,:,2] = (images[:,:,:,2] - bmean)#/bstd\n",
        "\tprint 'R_mean:',rmean,'G_mean:',gmean,'B_mean:',bmean\n",
        "\tprint 'R_stddev:',rstd,'G_stddev:',gstd,'B_stddev:',bstd\n",
        "\treturn images,rmean,gmean,bmean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EmhgTVvT5KuA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Function for getting Labels***"
      ]
    },
    {
      "metadata": {
        "id": "oruHiKS55Gov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_all_labels(label_file):\n",
        "\tlabels = np.fromfile(label_file,dtype=np.uint8)\n",
        "\t#print labels.shape\n",
        "\treturn labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70pY2qY85InY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Function for getting Test Images***"
      ]
    },
    {
      "metadata": {
        "id": "BLoGAh405ISv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_test_images(img_file,rmean,gmean,bmean):\n",
        "\timages = np.fromfile(img_file,dtype=np.uint8).astype(np.float32)\n",
        "\timages = np.reshape(images,(-1,3,96,96))\n",
        "\timages = np.transpose(images,(0,3,2,1))\n",
        "\tprint 'Normalizing Validation Images...'\n",
        "\timages[:,:,:,0] = (images[:,:,:,0] - rmean)#/rstd\n",
        "\timages[:,:,:,1] = (images[:,:,:,1] - gmean)#/gstd\n",
        "\timages[:,:,:,2] = (images[:,:,:,2] - bmean)#/bstd\n",
        "\treturn images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZhCc45c5R72",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Uploading Local Data**"
      ]
    },
    {
      "metadata": {
        "id": "VFbOtwR-6ljc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3oevjuKc_SH5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Getting the Data**"
      ]
    },
    {
      "metadata": {
        "id": "Ff-u71pY_a2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_path='train_X.bin'\n",
        "train_label_path='train_y.bin'\n",
        "\n",
        "train_img_file=open(train_data_path,'rb')\n",
        "train_label_file=open(train_label_path,'rb')\n",
        "\n",
        "train_x,rmean,gmean,bmean = get_all_images(train_img_file)\n",
        "train_y = get_all_labels(train_label_file)\n",
        "train_y = train_y-1\n",
        "\n",
        "#Getting Validation Dataset\n",
        "test_img_path = 'test_X.bin'\n",
        "test_label_path = 'test_y.bin'\n",
        "\n",
        "test_img_file = open(test_img_path,'rb')\n",
        "test_label_file = open(test_label_path,'rb')\n",
        "\n",
        "test_x = get_test_images(test_img_file,rmean,gmean,bmean)\n",
        "test_y = get_all_labels(test_label_file)\n",
        "print'Getting Validation set from Test set...'\n",
        "val_x = test_x[300:500]\n",
        "val_y = test_y[300:500]\n",
        "val_y = val_y-1 #Label values converted from [1,10] to [0,10)\n",
        "\n",
        "test_x = test_x[0:300]\n",
        "test_y = test_y[0:300]\n",
        "test_y = test_y-1\n",
        "\n",
        "index = np.arange(train_x.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfAa_uyYAGiI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Variables and Placeholders**"
      ]
    },
    {
      "metadata": {
        "id": "E6OZd58KAKSk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init_count = 0\n",
        "num_epochs = 100\n",
        "batch_size = 50\n",
        "numiter = 100\n",
        "ne = 0\n",
        "valacc = []\n",
        "#Create Placeholders\n",
        "feed_images = tf.placeholder(tf.float32,shape=(None,96,96,3))\n",
        "feed_labels = tf.placeholder(tf.float32,shape=(None,))\n",
        "\n",
        "lr = tf.placeholder(tf.float32,shape=())\n",
        "keep_prob = tf.placeholder(tf.float32,shape=())\n",
        "\n",
        "aug_img = tf.placeholder(tf.float32,shape=(96,96,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BvBwGdHkAZg_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Architecture***"
      ]
    },
    {
      "metadata": {
        "id": "T0C29b0QAc7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#VGG13 Net Model\n",
        "conv1 = conv2d(feed_images,'conv1',[3,3,3,64],1)\n",
        "conv2 = conv2d(conv1,'conv2',[3,3,64,64],1)\n",
        "pool1 = maxpool(conv2,'pool1',2,2)\n",
        "#size = [N,48,48,64]\n",
        "conv3 = conv2d(pool1,'conv3',[3,3,64,128],1)\n",
        "conv4 = conv2d(conv3,'conv4',[3,3,128,128],1)\n",
        "pool2 = maxpool(conv4,'pool2',2,2)\n",
        "#size = [N,24,24,128]\n",
        "conv5 = conv2d(pool2,'conv5',[3,3,128,256],1)\n",
        "conv6 = conv2d(conv5,'conv6',[3,3,256,256],1)\n",
        "conv7 = conv2d(conv6,'conv7',[3,3,256,256],1)\n",
        "pool3 = maxpool(conv7,'pool3',2,2)\n",
        "#size = [N,12,12,256]\n",
        "conv8 = conv2d(pool3,'conv8',[3,3,256,512],1)\n",
        "conv9 = conv2d(conv8,'conv9',[3,3,512,512],1)\n",
        "conv10 = conv2d(conv9,'conv10',[3,3,512,512],1)\n",
        "pool4 = maxpool(conv10,'pool4',2,2)\n",
        "#size = [N,6,6,512]\n",
        "conv11 = conv2d(pool4,'conv11',[3,3,512,512],1)\n",
        "conv12 = conv2d(conv11,'conv12',[3,3,512,512],1)\n",
        "conv13 = conv2d(conv12,'conv13',[3,3,512,512],1)\n",
        "pool5 = maxpool(conv13,'pool5',2,2)\n",
        "#size = [N,3,3,512]\n",
        "pool5shape = pool5.get_shape().as_list()\n",
        "N = pool5shape[1]*pool5shape[2]*pool5shape[3]\n",
        "flattened_pool5 = tf.contrib.layers.flatten(pool5)\n",
        "fc1 = tf.contrib.layers.fully_connected(flattened_pool5,4096,weights_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005, dtype=tf.float32)))\n",
        "dropout1 = tf.nn.dropout(fc1,keep_prob)\n",
        "fc2 = tf.contrib.layers.fully_connected(dropout1,4096,weights_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005, dtype=tf.float32)))\n",
        "dropout2 = tf.nn.dropout(fc2,keep_prob)\n",
        "logits = tf.contrib.layers.fully_connected(dropout2,10,activation_fn=None,weights_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005, dtype=tf.float32)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}